{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import word2vec\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from OpenFabLibrary import JeibaCutWords\n",
    "from OpenFabLibrary import AppendKeywordCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create word ID mapping and word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/\".join((\".\", \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2id_len: 50100\n"
     ]
    }
   ],
   "source": [
    "#w2v = word2vec.Word2Vec.load('word2vec_model/CBOW')\n",
    "w2v = word2vec.Word2Vec.load('word2vec_model/zh.bin')\n",
    "word2id = {k:i for i, k in enumerate(w2v.wv.vocab.keys())}\n",
    "id2word = {i:k for k, i in word2id.items()}\n",
    "word2id_len = len(word2id) - 1\n",
    "print('word2id_len:', word2id_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  AI預測 + 關鍵字檢查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_validation(input_text):\n",
    "    single_ad = 1  # 若是單一則廣告輸入，設 1\n",
    "               # 若是一大批廣告輸入，設 0\n",
    "        \n",
    "    ad_ID = 0\n",
    "    ad_Name = \"測試產品\"\n",
    "    ad_Class = 0\n",
    "\n",
    "    ad_Description = input_text\n",
    "    \n",
    "    if single_ad:\n",
    "        # 單一廣告輸入\n",
    "        test_data_df = pd.DataFrame({'ID': [ad_ID], \n",
    "                                     'Name':[ad_Name],\n",
    "                                     'Description':[ad_Description],\n",
    "                                     'Class':[ad_Class]})\n",
    "    else:\n",
    "        # 大批廣告輸入\n",
    "        test_data_source = \"test_private.csv\"\n",
    "        test_data_df = pd.read_csv(open(data_dir + '/' + test_data_source, 'r', encoding='utf8'), delimiter=',')\n",
    "\n",
    "\n",
    "    # 斷詞處理\n",
    "    test_df = JeibaCutWords(test_data_df)\n",
    "\n",
    "    # 關鍵字檢查\n",
    "    test_df['keyword_flag'], keywords_list = AppendKeywordCheck(test_df)\n",
    "    \n",
    "    #\n",
    "    # 選取多少詞來當作輸入\n",
    "    #\n",
    "    PICK_WORDS = 40  # 選前面40個詞當作輸入，這個長度要跟訓練模型的長度一樣\n",
    "    batch_size = 16  # 若是資料筆數很多，一次讀batch_size筆資料來預測\n",
    "\n",
    "    docs_pred_id = []\n",
    "    for doc in test_df['sentence']:\n",
    "        text = doc[:PICK_WORDS]\n",
    "        ids = [word2id_len+1]*PICK_WORDS\n",
    "        ids[:len(text)] = [word2id[w] if w in word2id else word2id_len+1 for w in text]\n",
    "        docs_pred_id.append(ids)\n",
    "\n",
    "    # 轉換後的sequence合併到dataframe    \n",
    "    test_df['sentence_seq'] = docs_pred_id\n",
    "\n",
    "    x = test_df['sentence_seq'].tolist()\n",
    "    X_pred = np.array(x)\n",
    "    y_actual = test_df['class'].as_matrix()\n",
    "    y_keyword_flag = test_df['keyword_flag'].as_matrix()\n",
    "    \n",
    "    #\n",
    "    # Load trained model and feed data to predict\n",
    "    #\n",
    "    pred_input = X_pred\n",
    "    pred_batch_size = batch_size\n",
    "    output_class = []\n",
    "    output_probability = []\n",
    "\n",
    "    with tf.gfile.GFile(\"./model/frozen_model.pb\", \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        # The name var will prefix every op/nodes in your graph\n",
    "        # Since we load everything in a new graph, this is not needed\n",
    "        tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "        \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        #saver = tf.train.import_meta_graph('./model/lstm_model.meta')\n",
    "        #saver.restore(sess, tf.train.latest_checkpoint('./model/'))\n",
    "        #graph = tf.get_default_graph()\n",
    "            \n",
    "        inputs = graph.get_tensor_by_name('prefix/input_layer/input_data:0')\n",
    "        keep_prob = graph.get_tensor_by_name('prefix/input_layer/keep_prob:0')\n",
    "        class_prob = graph.get_tensor_by_name('prefix/output_layer/class_probability:0')\n",
    "        #predict_out = graph.get_tensor_by_name('prefix/evaluate/predictions:0')\n",
    "        \n",
    "        for start in range(0, len(pred_input), pred_batch_size):\n",
    "            end = min(start + batch_size, len(pred_input))\n",
    "\n",
    "            x_pred_batch = pred_input[start:end]        \n",
    "\n",
    "            if np.ndim(x_pred_batch)==1:\n",
    "                x_pred_batch = x_pred_batch.reshape([1,-1])\n",
    "\n",
    "            #\n",
    "            # 把剛剛載入的模型拿來用\n",
    "            #\n",
    "            #pred_result, pred_prob = sess.run([predict_out, class_prob],\n",
    "            #                                  feed_dict = {inputs:x_pred_batch})\n",
    "            pred_prob = sess.run([class_prob], feed_dict = {inputs:x_pred_batch, keep_prob:1})\n",
    "            pred_result = np.around(pred_prob)  #四捨五入，機率 > 0.5，視為class \"1\"\n",
    "\n",
    "            output_class.extend(pred_result)\n",
    "            output_probability.extend(pred_prob)\n",
    "\n",
    "    # 預測的類別\n",
    "    y_pred_class = output_class\n",
    "    \n",
    "\n",
    "    # 預測的類別機率值\n",
    "    #kvdbg-Legal_prob = output_probability[:,0]    # column[0]是class 0的機率\n",
    "    #kvdbg-Violate_prob = output_probability[:,1]  # column[1]是class 1的機率\n",
    "    \n",
    "    if single_ad:\n",
    "        # 單一廣告判別\n",
    "        if y_pred_class[0] == 0:\n",
    "            keywords_list = []  # 合法廣告不用列出違規關鍵字\n",
    "            return \"合法\", output_probability, keywords_list\n",
    "        else:\n",
    "            return \"違法\", output_probability, keywords_list\n",
    "    else:\n",
    "        # 大批廣告判別\n",
    "        return y_pred_class, output_probability, keywords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入測試資料集，並進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\Users\\User\\Desktop\\AIGO\\Jeiba\\dict.txt.big ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.ub75bbb3384af150c32db207c6bfbd71d.cache\n",
      "Loading model cost 1.451 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "辨識結果:  違法\n",
      "違規機率:  [array([[0.998085]], dtype=float32)]\n",
      "違規字詞:  ['服用', '增強', '強化', '改善', '開胃']\n"
     ]
    }
   ],
   "source": [
    "# 單一廣告\n",
    "ad_text = \"含500億活菌數及八種益生菌，排便不順，氣味難聞，當心健康拉警報\\\n",
    "服用本產品可達到體內環保、增強抵抗力並強化細胞功能，可改善體質、促進新陳代謝、幫助維持消化道機能、促進食慾、開胃，促進腸道蠕動改變細菌叢生態，使排便順暢。\\\n",
    "\"\n",
    "\n",
    "result, probability, keywords = jieba_validation(ad_text)\n",
    "\n",
    "print(\"辨識結果: \", result)\n",
    "print(\"違規機率: \", probability)\n",
    "print(\"違規字詞: \", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
